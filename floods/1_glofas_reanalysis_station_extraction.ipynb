{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "138d0500-3f61-462b-94dc-4b86d3f30f0f",
   "metadata": {},
   "source": [
    "Script to extract GloFAS reanalysis data at station locations stored in an s3 bucket. Metadata file is used to identify which station points to extract (use Lisflood x and y coordinates if available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58d1358f-e55f-48c3-98a2-2c2302e82ccb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import dask\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6d2b84c-7d8b-479a-b5ed-19302848c37a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "country = 'mozambique'  # define country of interest\n",
    "#directory = Path(f'/s3/scratch/jamie.towner/flood_aa/{country}')  # define main working directory\n",
    "directory = Path(r\"C:\\Users\\15133\\Documents\\WFP\\flood_hazard\\flood_aa\\MOZ_training\")  # define main working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd9bec4a-06f2-4d85-a712-f0b539cf789f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up the S3 path for the Zarr files\n",
    "# store = f\"s3://wfp-seasmon/input/cds/glofas-historical/saf/01/*.zarr\"\n",
    "\n",
    "# # Set up connection to s3 store\n",
    "# s3 = s3fs.S3FileSystem.current()\n",
    "\n",
    "# # Fetch list of .zarr stores (files)\n",
    "# remote_files = s3.glob(store)\n",
    "# store = [\n",
    "#     s3fs.S3Map(root=f\"s3://{file}\", s3=s3, check=False) for file in remote_files\n",
    "# ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa29a131-2858-4e5e-aa59-f1ed7d694ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = list(Path.glob(directory / \"data/forecasts/glofas_reanalysis/\", \"*.zarr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "588c4791-5104-4d27-8b97-9d696872a93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file containing station information (i.e., station name, lat, lon)\n",
    "# define paths to data\n",
    "station_info = pd.read_csv(directory / \"data/metadata/metadata_observations.csv\")\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "out_dir = directory / \"data/forecasts/glofas_reanalysis\"\n",
    "Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# select only chokwe station for training\n",
    "station_info = station_info[station_info['station name'] == 'Limpopo_em_Chokwe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b554a8cb-61d0-456f-99b4-48890331fc92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store data for each station\n",
    "station_data = {}\n",
    "\n",
    "# Initialize tqdm with the total number of iterations to track progress\n",
    "# total_iterations = len(remote_files) * len(station_info)\n",
    "# pbar = tqdm(total=total_iterations, desc=\"Extracting Data\")\n",
    "\n",
    "# Open multiple .zarr files with dask and xarray, setting chunk configuration\n",
    "with dask.config.set(**{\"array.slicing.split_large_chunks\": True}):\n",
    "    ds = xr.open_mfdataset(\n",
    "        store,\n",
    "        decode_coords=\"all\",\n",
    "        engine=\"zarr\",\n",
    "        parallel=True,  # Enable parallel processing for speed-up\n",
    "        combine=\"by_coords\"\n",
    "    )\n",
    "\n",
    "    # Loop over each station in the station_info CSV\n",
    "    for index, row in station_info.iterrows():\n",
    "        point_name = row['station name']\n",
    "        latitude = row['lisflood_y']\n",
    "        longitude = row['lisflood_x']\n",
    "        if np.isnan(latitude) or np.isnan(longitude):\n",
    "            latitude = row['latitude']\n",
    "            longitude = row['longitude']\n",
    "\n",
    "        # Replace 'lat' and 'lon' with 'latitude' and 'longitude'\n",
    "        lat_index = ds['latitude'].sel(latitude=latitude, method='nearest').values\n",
    "        lon_index = ds['longitude'].sel(longitude=longitude, method='nearest').values\n",
    "\n",
    "        # Extract river discharge data for the nearest point\n",
    "        data_at_point = ds['dis24'].sel(latitude=lat_index, longitude=lon_index).values\n",
    "        dates = ds.time.values\n",
    "\n",
    "        # Convert dates to DD/MM/YYYY format\n",
    "        formatted_dates = pd.to_datetime(dates).strftime('%d/%m/%Y')\n",
    "\n",
    "        # Create a DataFrame for the extracted data\n",
    "        extracted_df = pd.DataFrame({'date': formatted_dates, 'river discharge': data_at_point})\n",
    "\n",
    "        # Append the data to the station's DataFrame within the station_data dictionary\n",
    "        if point_name not in station_data:\n",
    "            station_data[point_name] = extracted_df\n",
    "        else:\n",
    "            # Merge with the existing data for the same station\n",
    "            station_data[point_name] = pd.concat([station_data[point_name], extracted_df])\n",
    "        \n",
    "        #pbar.update(len(remote_files))  # Update tqdm progress by number of files processed\n",
    "\n",
    "# Close the tqdm progress bar\n",
    "#pbar.close()\n",
    "\n",
    "# Save extracted data for each station to CSV files\n",
    "for station, data in station_data.items():\n",
    "    csv_file_name = os.path.join(out_dir, f\"{station}.csv\")\n",
    "    data.to_csv(csv_file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a9cd343-d549-405b-a2b5-9bf38657f58a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Limpopo_em_Chokwe</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01/01/1979</th>\n",
       "      <td>118.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02/01/1979</th>\n",
       "      <td>100.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/01/1979</th>\n",
       "      <td>87.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04/01/1979</th>\n",
       "      <td>77.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05/01/1979</th>\n",
       "      <td>71.640625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27/12/2023</th>\n",
       "      <td>233.664062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28/12/2023</th>\n",
       "      <td>450.976562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29/12/2023</th>\n",
       "      <td>764.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/12/2023</th>\n",
       "      <td>1028.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/12/2023</th>\n",
       "      <td>1180.554688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16436 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Limpopo_em_Chokwe\n",
       "date                         \n",
       "01/01/1979         118.546875\n",
       "02/01/1979         100.890625\n",
       "03/01/1979          87.375000\n",
       "04/01/1979          77.765625\n",
       "05/01/1979          71.640625\n",
       "...                       ...\n",
       "27/12/2023         233.664062\n",
       "28/12/2023         450.976562\n",
       "29/12/2023         764.796875\n",
       "30/12/2023        1028.093750\n",
       "31/12/2023        1180.554688\n",
       "\n",
       "[16436 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dfs = []\n",
    "for station, data in station_data.items():\n",
    "    name = \"\".join(c for c in station if c.isalnum() or c in (' ', '_')).replace(' ', '_')\n",
    "    data = data.rename(columns={'river discharge':name})\n",
    "    data = data.set_index('date')\n",
    "    all_dfs.append(data)\n",
    "pd.concat(all_dfs,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c895d37-2ea3-471b-9356-fae5d8577642",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_file_name = os.path.join(out_dir, f\"all_stations/glofas_reanalysis_complete_series.csv\")\n",
    "pd.concat(all_dfs,axis=1).to_csv(csv_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f938830b-6ec0-4eaf-9127-6b3c0fecad5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_file_name = os.path.join(out_dir, f\"all_stations/glofas_reanalysis.csv\")\n",
    "\n",
    "df_all = pd.concat(all_dfs,axis=1)\n",
    "df_all.index = pd.to_datetime(df_all.index,format='%d/%m/%Y')\n",
    "df_all[df_all.index>='01/01/2003'].to_csv(csv_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d6e1b5-f01f-4052-a7d9-87186c388e3b",
   "metadata": {},
   "source": [
    "### get correlation of observed data with glofas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "238575f1-1e79-4716-ac04-574a1a708271",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Limpopo_em_Mapai</th>\n",
       "      <th>Limpopo__Combomune</th>\n",
       "      <th>Limpopo_em_Chokwe</th>\n",
       "      <th>Limpopo_em_Sicacate</th>\n",
       "      <th>Limpopo_em_Mabalane</th>\n",
       "      <th>Limpopo_em_XaiXai</th>\n",
       "      <th>Changane_em_VGomes_da_Costa</th>\n",
       "      <th>Changane_em_Chibuto</th>\n",
       "      <th>Limpopo_em_Macaretane</th>\n",
       "      <th>Elefantes_em_Munhamane</th>\n",
       "      <th>Singuezi_em_Bingo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.88</td>\n",
       "      <td>2.150000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>1.305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.870000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.51</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.160000</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>1.150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.880000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.170000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>1.330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.903333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>1.610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.906667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.170000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>1.710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.920000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7670 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Limpopo_em_Mapai  Limpopo__Combomune  Limpopo_em_Chokwe  \\\n",
       "date                                                                  \n",
       "2003-01-01               NaN                1.50               0.88   \n",
       "2003-01-02               NaN                1.51               0.89   \n",
       "2003-01-03               NaN                1.52               0.89   \n",
       "2003-01-04               NaN                1.53               0.89   \n",
       "2003-01-05               NaN                1.54               0.89   \n",
       "...                      ...                 ...                ...   \n",
       "2023-12-27               NaN                 NaN                NaN   \n",
       "2023-12-28               NaN                 NaN                NaN   \n",
       "2023-12-29               NaN                 NaN                NaN   \n",
       "2023-12-30               NaN                 NaN                NaN   \n",
       "2023-12-31               NaN                 NaN                NaN   \n",
       "\n",
       "            Limpopo_em_Sicacate  Limpopo_em_Mabalane  Limpopo_em_XaiXai  \\\n",
       "date                                                                      \n",
       "2003-01-01             2.150000             0.930000              1.305   \n",
       "2003-01-02             2.160000             0.926667              1.150   \n",
       "2003-01-03             2.170000             0.920000              1.330   \n",
       "2003-01-04             2.166667             0.920000              1.610   \n",
       "2003-01-05             2.170000             0.910000              1.710   \n",
       "...                         ...                  ...                ...   \n",
       "2023-12-27                  NaN                  NaN                NaN   \n",
       "2023-12-28                  NaN                  NaN                NaN   \n",
       "2023-12-29                  NaN                  NaN                NaN   \n",
       "2023-12-30                  NaN                  NaN                NaN   \n",
       "2023-12-31                  NaN                  NaN                NaN   \n",
       "\n",
       "            Changane_em_VGomes_da_Costa  Changane_em_Chibuto  \\\n",
       "date                                                           \n",
       "2003-01-01                          NaN                  NaN   \n",
       "2003-01-02                          NaN                  NaN   \n",
       "2003-01-03                          NaN                  NaN   \n",
       "2003-01-04                          NaN                  NaN   \n",
       "2003-01-05                          NaN                  NaN   \n",
       "...                                 ...                  ...   \n",
       "2023-12-27                          NaN                  NaN   \n",
       "2023-12-28                          NaN                  NaN   \n",
       "2023-12-29                          NaN                  NaN   \n",
       "2023-12-30                          NaN                  NaN   \n",
       "2023-12-31                          NaN                  NaN   \n",
       "\n",
       "            Limpopo_em_Macaretane  Elefantes_em_Munhamane  Singuezi_em_Bingo  \n",
       "date                                                                          \n",
       "2003-01-01              96.870000                     NaN                NaN  \n",
       "2003-01-02              96.880000                     NaN                NaN  \n",
       "2003-01-03              96.903333                     NaN                NaN  \n",
       "2003-01-04              96.906667                     NaN                NaN  \n",
       "2003-01-05              96.920000                     NaN                NaN  \n",
       "...                           ...                     ...                ...  \n",
       "2023-12-27                    NaN                     NaN                NaN  \n",
       "2023-12-28                    NaN                     NaN                NaN  \n",
       "2023-12-29                    NaN                     NaN                NaN  \n",
       "2023-12-30                    NaN                     NaN                NaN  \n",
       "2023-12-31                    NaN                     NaN                NaN  \n",
       "\n",
       "[7670 rows x 11 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_obs = pd.read_csv(directory / 'data/observations/gauging_stations/all_stations/observations.csv')\n",
    "df_obs = df_obs.rename(columns={'Unnamed: 0':'date'})\n",
    "df_obs[\"date\"] = pd.to_datetime(df_obs[\"date\"], format='mixed')\n",
    "df_obs = df_obs.set_index('date')\n",
    "df_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4de7ab56-be6b-44c6-a5de-d7af218a0e66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Limpopo_em_Chokwe              0.510731\n",
       "Changane_em_Chibuto                 NaN\n",
       "Changane_em_VGomes_da_Costa         NaN\n",
       "Elefantes_em_Munhamane              NaN\n",
       "Limpopo__Combomune                  NaN\n",
       "Limpopo_em_Mabalane                 NaN\n",
       "Limpopo_em_Macaretane               NaN\n",
       "Limpopo_em_Mapai                    NaN\n",
       "Limpopo_em_Sicacate                 NaN\n",
       "Limpopo_em_XaiXai                   NaN\n",
       "Singuezi_em_Bingo                   NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[df_all.index>='01/01/2003'].corrwith(df_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d956101a-9d4f-4ea7-9437-a676bd4a5586",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Pixi)",
   "language": "python",
   "name": "pixi-kernel-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
