{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201206d9-e416-4e88-b111-5d5e7c9d3263",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# set column fixed widths\n",
    "col_widths = [14] + [9]*12\n",
    "\n",
    "# read the .OUT file, skipping the first 13 rows of station info\n",
    "df = pd.read_fwf(\n",
    "    '/s3/scratch/jamie.towner/flood_aa/zimbabwe/data/observations/raw_data/F22D.OUT',\n",
    "    widths=col_widths,\n",
    ")\n",
    "\n",
    "# get month column names\n",
    "columns = ['Day'] + list(df.iloc[8].values[1:]) + ['Year']\n",
    "\n",
    "# add year column\n",
    "df['Year'] = \"\"\n",
    "for l in range(5,len(df),51):\n",
    "    start = l+4\n",
    "    end = l+4+31\n",
    "    df.loc[start:end,'Year'] = \"\".join(df.iloc[l].values[6:8])\n",
    "\n",
    "# read the first 31 out of every 52 rows\n",
    "def get_rows_to_skip(df, n, start, end, flen):\n",
    "    rows_to_skip = [i for i in range(flen) if i % n < start or i % n >= end]\n",
    "    return rows_to_skip\n",
    "\n",
    "n = 51\n",
    "start = 9\n",
    "end = 40\n",
    "flen = len(df)\n",
    "\n",
    "skiprows = get_rows_to_skip(df, n, start, end, flen)\n",
    "\n",
    "# get only rows that are not skipped\n",
    "df2 = df[~df.index.isin(skiprows)]\n",
    "\n",
    "# set column name to months and index to year and day\n",
    "df2.columns = columns\n",
    "df2 = df2.set_index(['Year','Day'])\n",
    "\n",
    "df2.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab4f2db-7213-40dc-93a5-e69975551296",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace '*' with NaN (assuming df2 is your dataframe)\n",
    "df2.replace('*', np.nan, inplace=True)\n",
    "\n",
    "# Step 1: Reset the index to make 'Day' a column\n",
    "df2_reset = df2.reset_index()\n",
    "\n",
    "# Step 2: Melt the DataFrame to long format\n",
    "df_long = df2_reset.melt(id_vars=['Year', 'Day'], var_name='Month', value_name='Discharge')\n",
    "\n",
    "# Step 3: Map month names to numbers, starting from October (OCT = 10, etc.)\n",
    "month_map = {\n",
    "    'OCT': 10, 'NOV': 11, 'DEC': 12, 'JAN': 1, 'FEB': 2, 'MAR': 3,\n",
    "    'APR': 4, 'MAY': 5, 'JUN': 6, 'JUL': 7, 'AUG': 8, 'SEP': 9\n",
    "}\n",
    "df_long['Month_num'] = df_long['Month'].map(month_map)\n",
    "\n",
    "# Step 4: Extract the starting year from the \"Year\" column\n",
    "df_long['Start_Year'] = df_long['Year'].str.split('/').str[0].astype(int)\n",
    "\n",
    "# Step 5: Adjust the year for Jan-Sep (shift by 1 year)\n",
    "df_long['Adjusted_Year'] = df_long.apply(lambda row: row['Start_Year'] if row['Month_num'] >= 10 else row['Start_Year'] + 1, axis=1)\n",
    "\n",
    "# Step 6: Manually set the first date as 01/10/1959 and handle subsequent dates.\n",
    "def create_date(row):\n",
    "    if row['Month_num'] == 10 and row['Day'] == 1 and row['Adjusted_Year'] == 1959:\n",
    "        # Explicitly set the first date\n",
    "        return pd.to_datetime(\"1959-10-01\")\n",
    "    else:\n",
    "        try:\n",
    "            # Calculate the exact date based on the Year, Month, and Day\n",
    "            date_str = f\"{row['Adjusted_Year']}-{row['Month_num']}-{row['Day']}\"\n",
    "            date = pd.to_datetime(date_str, errors='coerce')  # Handle invalid dates\n",
    "            return date\n",
    "        except Exception as e:\n",
    "            print(f\"Error with row {row}: {e}\")\n",
    "            return pd.NaT  # Return NaT for invalid rows\n",
    "\n",
    "# Step 7: Apply the function to create the date column\n",
    "df_long['Date'] = df_long.apply(create_date, axis=1)\n",
    "\n",
    "# Step 8: Remove rows where Date is NaT (invalid date rows)\n",
    "df_long = df_long.dropna(subset=['Date'])\n",
    "\n",
    "# Step 9: Sort by Date to ensure chronological order\n",
    "df_long.sort_values(by='Date', inplace=True)\n",
    "\n",
    "# Step 10: Reset index after sorting\n",
    "df_long.reset_index(drop=True, inplace=True)\n",
    "\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "# Step 11: Print the first few rows to verify\n",
    "#print(df_long[['Date', 'Discharge']].head(100))\n",
    "\n",
    "df_long = df_long[['Date', 'Discharge']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66665059-f64b-4a17-850c-5a69b0123b98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the first date in df_long\n",
    "#start_date = df_long['Date'].min()\n",
    "start_date = '2003-01-01'\n",
    "end_date = '2023-12-31'\n",
    "\n",
    "# Define full date range from start to end\n",
    "full_date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "# Create a new DataFrame with the full date range\n",
    "df_complete = pd.DataFrame({'Date': full_date_range})\n",
    "\n",
    "# Select only the necessary columns from the original DataFrame\n",
    "df_filtered = df_long[['Date', 'Discharge']]\n",
    "\n",
    "# Merge to insert missing dates and fill with NaN\n",
    "df_filtered = pd.merge(df_complete, df_filtered, on='Date', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae79a746-bf02-4504-b64c-92da5a2abe31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define full date range from start to end\n",
    "full_date_range = pd.date_range(start='2003-01-01', end='2023-12-31', freq='D')\n",
    "\n",
    "# Filter to include only October–April months\n",
    "oct_apr_range = full_date_range[full_date_range.month.isin([10, 11, 12, 1, 2, 3, 4])]\n",
    "\n",
    "# Create a new DataFrame with the full Oct–Apr date range\n",
    "df_complete = pd.DataFrame({'Date': oct_apr_range})\n",
    "\n",
    "# Merge with your filtered df_long to fill missing dates with NaN\n",
    "df_filtered = df_long[['Date', 'Discharge']]\n",
    "df_filtered = pd.merge(df_complete, df_filtered, on='Date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cc447d-6613-489e-8b53-6defbaa3a4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.loc[:, 'Discharge'] = pd.to_numeric(df_filtered['Discharge'], errors='coerce')\n",
    "count = (df_filtered['Discharge'] >= 461.6 ).sum()\n",
    "print(f\"Number of times 'Discharge' >= thresold: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1800cb-5260-4a18-b651-b5321230c5e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Total number of values in the 'Discharge' column\n",
    "total_values = df_filtered['Discharge'].size\n",
    "\n",
    "# Total number of missing values in the 'Discharge' column\n",
    "missing_values = df_filtered['Discharge'].isna().sum()\n",
    "\n",
    "# Percentage of missing values\n",
    "missing_percentage = (missing_values / total_values) * 100\n",
    "\n",
    "result = 100 - missing_percentage\n",
    "\n",
    "print(f\"Percentage of : {result:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f833c8-c382-405a-8fd7-4a5e04a4a0af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_filtered.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dbecc1-6c02-4567-838f-8c93764123cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"/s3/scratch/jamie.towner/flood_aa/zimbabwe/data/observations/gauging_stations/katiyo.csv\"\n",
    "df_long.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hdc",
   "language": "python",
   "name": "conda-env-hdc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
