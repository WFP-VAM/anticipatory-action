{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "848602b5",
   "metadata": {},
   "source": [
    "## Run full AA drought verification\n",
    "\n",
    "#### (can be used for a more user-friendly experience or for training purposes)\n",
    "\n",
    "This notebook is intended to be self-sufficient for executing the entire workflow operationally ahead of the season and get the triggers using specific parameters and specific datasets. It is designed to be interactive, and does not require any direct interaction with another file, except for the configuration file. This will therefore be the main front-end for Anticipatory Action analysts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf58014",
   "metadata": {},
   "source": [
    "If you have not downloaded the data yet, please download it from the link you should have received by email."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b120aa",
   "metadata": {},
   "source": [
    "**Import required libraries and functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadf8254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "from hip.analysis.aoi.analysis_area import AnalysisArea\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "from AA.analytical import run_issue_verification\n",
    "from AA.helper_fns import get_coverage, read_forecasts, read_observations\n",
    "from AA.triggers import run_triggers_selection\n",
    "from config.params import Params\n",
    "\n",
    "if os.getcwd().split('\\\\')[-1] != \"anticipatory-action\":\n",
    "    os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbac872d-db8e-4635-b8e2-4b6ce0f4a31e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "**First, please define the country ISO code and the index of interest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ece5205-edb0-47a6-8bb1-5113d9dfa8b4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "country = \"ISO\"\n",
    "index = \"SPI\"  # 'SPI' or 'DRYSPELL'\n",
    "data_path = \".\" # current directory (anticipatory-action)\n",
    "output_path = \".\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4c5e2d-9cc2-4c65-8b18-a507075dc67f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Now, we will configure some parameters. Please feel free to edit the year of the last season considered. By default, it is equal to 2022. This means that for the purposes of evaluating and selecting triggers, the time series studied will end with the 2021-2022 season. This is the configuration chosen for monitoring the 2023-2024 season.\n",
    "\n",
    "Please also have a look at the `config/{iso}_config.yaml` file that contains all the defined parameters that are used in this workflow.\n",
    "\n",
    "*Note: if you change a parameter or a dataset, please make sure to manage correctly the different output paths so you don't overwrite previous results.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480175e8-4d55-4d59-93c8-00d523501f0e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "params = Params(\n",
    "    iso=country, index=index, data_path=data_path, output_path=output_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d88ec4e-c160-4e7a-ade2-359e497db8fd",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305bd8f0",
   "metadata": {},
   "source": [
    "Let's start by getting the Zimbabwe shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5e70fe",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "area = AnalysisArea.from_admin_boundaries(\n",
    "    iso3=params.iso.upper(),\n",
    "    admin_level=2,\n",
    "    resolution=0.25,\n",
    "    datetime_range=f\"1981-01-01/{params.calibration_year}-06-30\",\n",
    ")\n",
    "\n",
    "gdf = area.get_dataset([area.BASE_AREA_DATASET])\n",
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abe80c3-4bad-4a54-ad1e-b1f7ca20df9f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "The next cell reads the observations dataset. Please run it directly if you have the data stored in the specified path or have access to HDC.\n",
    "\n",
    "\n",
    "*Notes for more advanced usage:*\n",
    "\n",
    "If you want to read a dataset that you have stored locally, you can give its path as an argument to `read_observations`. However, please make sure you have the right dimensions (grid spanning the whole country and daily timesteps since 1981) and that the band name is 'band'.\n",
    "\n",
    "If you want to read another dataset, that will be possible soon by specifying your key as an argument. For now, it is accessible via hip-analysis (see this [doc](https://wfp-vam.github.io/hip-analysis/reference/datasources/) to explore all the available datasets), but you need to replace the product name (*rfh_daily*) with the substitute product name in `AA.helper_fns.read_observations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbb7b2c-6d07-44b9-a09f-dc6f06dda59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observations data reading\n",
    "observations = read_observations(\n",
    "    area,\n",
    "    f\"{params.data_path}/data/{params.iso}/zarr/{params.calibration_year}/obs/observations.zarr\",\n",
    ")\n",
    "observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20f96b0-52f3-4338-9f6b-864d88d0c797",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "As with observations, forecasts are easy to read using hip-analysis. When other datasets will be available there, it will also be possible to change these ECMWF forecasts to use another dataset from another source.\n",
    "\n",
    "If your dataset is not available via hip-analysis or if you already have stored locally the forecasts you would like to use, you can edit the path below and forecasts will be read in the analytical loop. Once again, make sure that your coordinates match those of the observations, that your forecasts are daily, and that you have 51 members. The name of the data variable must be 'tp'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5220ad8-d0ca-4e84-be8b-8f60d74925b4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "forecasts_folder_path = (\n",
    "    f\"{params.data_path}/data/{params.iso}/zarr/{params.calibration_year}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edbaa0f-85d8-4539-902d-6f2c71edf343",
   "metadata": {},
   "source": [
    "Congratulations! You've completed the part that requires the most energy during this process. Now all you have to do is run the different cells and check the results!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68482805-761e-4aae-9018-806c6d7ad274",
   "metadata": {},
   "source": [
    "### Analytical processing\n",
    "\n",
    "The next part contains the analytical phase of the AA process.\n",
    "\n",
    "This calculates the probabilities from the forecasts and the anomalies from the observations for all the issue months and the entire time series in order to measure the ROC score with and without bias correction. Probabilities and anomalies are saved locally, so that they can be reused during the trigger selection phase.\n",
    "\n",
    "*Note1: the next cell can take several hours to run if looping through all issue months, so please make sure before launching it that you have started a new instance of JupyterHub if working on it so it doesn't get interrupted.*\n",
    "\n",
    "*Note2: if you want to re-run the workflow for issue months that you have already processed before, please delete the roc scores files in the `auc/split_by_issue` folder for the issue months of interest. Otherwise, the script will directly load the roc scores from the local files.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ff1045-95f2-4a41-aced-faf96228c5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for ROC scores df per issue month in case it doesn't exist\n",
    "os.makedirs(\n",
    "    f\"{params.data_path}/data/{params.iso}/auc/split_by_issue\",\n",
    "    exist_ok=True,\n",
    ")\n",
    "\n",
    "# Define empty list for each issue month's ROC score dataframe\n",
    "fbf_roc_issues = []\n",
    "\n",
    "for issue in [\"07\", \"08\"]:  # params.issue_months:\n",
    "\n",
    "    forecasts = read_forecasts(\n",
    "        area,\n",
    "        issue,\n",
    "        f\"{forecasts_folder_path}/{issue}/forecasts.zarr\",\n",
    "    )\n",
    "    logging.info(f\"Completed reading of forecasts for the issue month {issue}\")\n",
    "\n",
    "    fbf_roc_issues.append(\n",
    "        run_issue_verification(\n",
    "            forecasts,\n",
    "            observations,\n",
    "            issue,\n",
    "            params,\n",
    "            area,\n",
    "        )\n",
    "    )\n",
    "    logging.info(\n",
    "        f\"Completed analytical process for {params.index.upper()} over {country} country\"\n",
    "    )\n",
    "\n",
    "fbf_roc = pd.concat(fbf_roc_issues)\n",
    "display(fbf_roc)  # noqa: F821"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4e4b0b-382f-4416-bcd6-7df1e530783f",
   "metadata": {},
   "source": [
    "Let's have a look at how the computed probabilities data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c4bab2-e392-407c-a562-fb1e46c018b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.open_zarr(f\"{forecasts_folder_path}/07/{params.index} OND/probabilities.zarr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40648f41-cb28-4754-bd88-aebe87cb466f",
   "metadata": {},
   "source": [
    "We can also check how the CHIRPS-based anomalies that have been saved look like. They have been used to calculate the roc scores and will be used to select the triggers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e38eaa6-e30e-4407-8441-454d7e6dcc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.open_zarr(f\"{forecasts_folder_path}/obs/{params.index} OND/observations.zarr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11999c93-7da7-4ddd-800d-5dbf336ed4a9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "By running the next cell, you can save the dataframe containing the ROC scores. We commented it here so we don't overwrite the file with all the issue months with a file that only contains a few issue months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631d89e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fbf_roc.to_csv(\n",
    "    f\"{params.data_path}/data/{params.iso}/auc/fbf.districts.roc.{params.index}.{params.calibration_year}.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602b2cd1-ea44-4c5c-888c-afa7ac87b326",
   "metadata": {},
   "source": [
    "Now we can read this dataframe locally to visualize the ROC scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ce9d42-dc8b-4fc1-8c87-5d4526e11d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = pd.read_csv(\n",
    "    f\"{params.data_path}/data/{params.iso}/auc/fbf.districts.roc.{params.index}.{params.calibration_year}.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9793d3f-39a0-4deb-b7cd-b7a070916480",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(  # noqa: F821\n",
    "    md(\n",
    "        f\"This roc file shows {round(100 * roc.BC.sum() / len(roc), 1)} % of bias-corrected values.\"\n",
    "    )\n",
    ")\n",
    "display(roc)  # noqa: F821\n",
    "\n",
    "# Filter to include only 'AUC_best' scores and pivot the table\n",
    "roc_pivot = roc.loc[\n",
    "    (roc.district.isin(params.districts)) & (roc.category.isin([\"Moderate\"]))\n",
    "].pivot_table(values=\"AUC_best\", index=\"Index\", columns=\"district\")\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(roc_pivot, annot=True, cmap=\"YlGnBu\", cbar_kws={\"label\": \"AUC_best\"})\n",
    "plt.title(\"AUC_best Scores Heatmap - Moderate\")\n",
    "plt.xlabel(\"District\")\n",
    "plt.ylabel(\"Index\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec201b93-5a5b-409e-8b16-ffa5b135b422",
   "metadata": {},
   "source": [
    "### Triggers selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a979346-cd4c-47e6-98cf-aba1a79ad2db",
   "metadata": {},
   "source": [
    "We've now come to the final part: the triggers optimization! All you have to do is execute the next cell and the calculations will take place automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ad0697",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Let's first define the vulnerability. We will run (if needed for at least one district) the triggers selection for two vulnerability levels: General Triggers & Non-Regret (or Emergency) Triggers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8b5b74",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "params.load_vulnerability_requirements(\"GT\")  # \"NRT\", \"TBD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f34c09-e0fb-44e2-8620-8a4342010fc6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "run_triggers_selection(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd35d9c2-d5af-41ca-be55-48a74f9d8b81",
   "metadata": {},
   "source": [
    "Then, we keep the best pair for each lead time and the 4 best pairs of triggers per window of activation (in terms of Hit Rate first, and Failure Rate then)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94045b2e-7a6d-4aa2-8df2-79373d40d075",
   "metadata": {},
   "source": [
    "The triggers dataframe has been saved here: `\"data/{iso}/triggers/triggers.aa.python.{index}.{calibration_year}.{vulnerability}.csv\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e963e7-cdcf-4a05-8632-0fc49d02939f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "triggers = pd.read_csv(\n",
    "    f\"{params.data_path}/data/{params.iso}/triggers/triggers.{params.index}.{params.calibration_year}.{params.vulnerability}.csv\",\n",
    ")\n",
    "triggers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb115a14",
   "metadata": {},
   "source": [
    "### Visualize coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a39cb88",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "columns = None\n",
    "# columns = [\"W1-Mild\", \"W1-Moderate\", \"W1-Severe\", \"W2-Mild\", \"W2-Moderate\", \"W2-Severe\"]\n",
    "# columns = [\"W1-Normal\", \"W2-Normal\"]\n",
    "get_coverage(triggers, triggers[\"district\"].sort_values().unique(), columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530485c2",
   "metadata": {},
   "source": [
    "Great! The pre-season verification is complete. You can now proceed with the operational script and process the forecasts when they are ready to produce the alerts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab5635a-38dc-4dcc-b713-ffce49785a96",
   "metadata": {},
   "source": [
    "Please find the final dataframe here!\n",
    "\n",
    "`data/{iso}/triggers/triggers.final.{monitoring_year}.pilots.csv`"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python (Pixi)",
   "language": "python",
   "name": "pixi-kernel-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
