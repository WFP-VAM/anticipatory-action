{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check *analytical* pipeline using datasets/parameters of interest by comparing results with reference outputs at the district level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import xskillscore as xss\n",
    "\n",
    "from odc.geo.geobox import GeoBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_fns import read_observations_locally, read_forecasts_locally, aggregate_by_district\n",
    "from config.params import Params\n",
    "from analytical import calculate_forecast_probabilities, evaluate_forecast_probabilities, get_verification_df\n",
    "from hip.analysis.analyses.drought import get_accumulation_periods\n",
    "from hip.analysis.aoi import AnalysisArea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = read_forecasts_locally('data/MOZ/forecast/Moz_SAB_tp_ecmwf_01/*.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Params(iso='MOZ', index='SPI')\n",
    "params.issue=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = read_observations_locally(f\"data/MOZ/chirps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triggers_df = pd.read_csv(f\"data/{params.iso}/outputs/Plots/triggers.aa.python.spi.dryspell.2022.csv\")\n",
    "gdf = gpd.read_file(f\"data/{params.iso}/shapefiles/moz_admbnda_2019_SHP/moz_admbnda_adm2_2019.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulation_periods = get_accumulation_periods(\n",
    "    fc, \n",
    "    params.start_season,\n",
    "    params.end_season,\n",
    "    params.min_index_period, \n",
    "    params.max_index_period\n",
    ")\n",
    "accumulation_periods\n",
    "period = accumulation_periods['AM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = fc.where(fc.time < np.datetime64('2022-07-01T12:00:00.000000000'), drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test functions for ```calculate_forecast_probabilities``` and ```evaluate_forecast_probabilities```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.year = 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_input(month=\"01\"):\n",
    "    np.random.seed(42)\n",
    "    test_input_fc = xr.Dataset(\n",
    "        data_vars=dict(\n",
    "            tp=([\"time\", \"ensemble\", \"longitude\", \"latitude\"], np.random.rand(len(range(1993, 2022)) * 31, 5, 3, 3)),\n",
    "        ),\n",
    "        coords = dict(\n",
    "            time=pd.concat([pd.Series(pd.date_range(f\"{yyyy}-{month}-01\", f\"{yyyy}-{month}-31\")) for yyyy in range(1993, 2022)]),\n",
    "            ensemble=range(5),\n",
    "            longitude=[-1, 0, 1],\n",
    "            latitude=[-1, 0, 1],\n",
    "        )\n",
    "    )\n",
    "    test_input_obs = xr.Dataset(\n",
    "        data_vars=dict(precip=([\"time\", \"longitude\", \"latitude\"], np.random.rand(len(range(1993, 2022)) * 31, 3, 3))),\n",
    "        coords = dict(\n",
    "            time=pd.concat([pd.Series(pd.date_range(f\"{yyyy}-{month}-01\", f\"{yyyy}-{month}-31\")) for yyyy in range(1993, 2022)]),\n",
    "            longitude=[-1, 0, 1],\n",
    "            latitude=[-1, 0, 1],\n",
    "        )\n",
    "    )\n",
    "    test_input_probas = xr.Dataset(\n",
    "        data_vars=dict(tp=([\"year\"], np.random.rand(len(range(1993, 2022))))),\n",
    "        coords = dict(year=range(1993, 2022))\n",
    "    )\n",
    "    np.random.seed(43)\n",
    "    test_input_probas_bc = xr.Dataset(\n",
    "        data_vars=dict(scen=([\"year\"], np.random.rand(len(range(1993, 2022))))),\n",
    "        coords = dict(year=range(1993, 2022))\n",
    "    )\n",
    "    test_input_levels = xr.Dataset(\n",
    "        data_vars=dict(precip=([\"year\"], np.random.randint(0, 2, len(range(1993, 2022))))),\n",
    "        coords = dict(year=range(1993, 2022))\n",
    "    )\n",
    "    return test_input_fc, test_input_obs, test_input_probas, test_input_probas_bc, test_input_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_calculate_forecast_probabilities():\n",
    "    np.random.seed(42)\n",
    "    test_input_fc1, test_input_obs1, _, _, _ = get_test_input(\"01\")\n",
    "    probabilities_a, bc_a, _, levels_obs_a = calculate_forecast_probabilities(test_input_fc1, test_input_obs1, params, (1), 1) \n",
    "    probabilities_b, bc_b, _, levels_obs_b = calculate_forecast_probabilities(test_input_fc1, test_input_obs1, params, (1), 12) \n",
    "    \n",
    "    ref_probas_month1 = xr.DataArray(\n",
    "        np.array([0.2, 0.2, 0.2, 0.2, 0.2, 0.13333333, 0.2, 0.2, 0.4, 0.2, 0., 0.06666667, 0., 0.2, 0.33333333, 0., 0.2, 0.2, 0.13333333, 0.2, 0.6, 0, 0.6, 0.33333333, 0.2, 0.2, 0.26666667, 0.13333333, 0.]),\n",
    "        coords=dict(year=range(1993, 2022))\n",
    "    ).assign_coords(dict(longitude=0, latitude=0))\n",
    "    ref_bc_month1_issue1 = xr.DataArray(\n",
    "        np.array([0.2, 0.26666667, 0.2, 0.33333333, 0.2, 0.06666667, 0.26666667, 0.2, 0.4, 0.26666667, 0., 0.06666667, 0., 0.2, 0.26666667, 0.06666667, 0.2, 0.13333333, 0.2, 0.2, 0.73333333, 0., 0.6, 0.33333333, 0.2, 0.2, 0.26666667, 0.2, 0.]),\n",
    "        coords=dict(year=range(1993, 2022))\n",
    "    ).assign_coords(dict(longitude=0, latitude=0))\n",
    "    ref_bc_month1_issue12 = xr.DataArray(\n",
    "        np.array([0.13333333, 0.26666667, 0.2, 0.13333333, 0.2, 0.2 , 0.26666667, 0.2 , 0.4, 0.26666667, 0., 0.06666667, 0., 0.2, 0.4, 0., 0.2, 0.2, 0.26666667, 0.2, 0.66666667, 0., 0.6, 0.46666667, 0.2, 0.2, 0.33333333, 0.2, 0]),\n",
    "        coords=dict(year=range(1993, 2022))\n",
    "    ).assign_coords(dict(longitude=0, latitude=0))\n",
    "    ref_obs_month1 = xr.DataArray(\n",
    "        np.array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0.66666667, 0, 0, 1, 0, 1, 0.33333333, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0.33333333]),\n",
    "        coords=dict(year=range(1993, 2022))\n",
    "    ).assign_coords(dict(longitude=0, latitude=0))\n",
    "\n",
    "    xr.testing.assert_allclose(probabilities_a.sel(latitude=0, longitude=0).mean('category').tp, ref_probas_month1)\n",
    "    xr.testing.assert_allclose(probabilities_b.sel(latitude=0, longitude=0).mean('category').tp, ref_probas_month1)\n",
    "\n",
    "    xr.testing.assert_allclose(bc_a.sel(latitude=0, longitude=0).mean('category').scen, ref_bc_month1_issue1)\n",
    "    xr.testing.assert_allclose(bc_b.sel(latitude=0, longitude=0).mean('category').scen, ref_bc_month1_issue12)\n",
    "    \n",
    "    xr.testing.assert_allclose(levels_obs_a.sel(latitude=0, longitude=0).mean('category').precip, ref_obs_month1)\n",
    "    xr.testing.assert_allclose(levels_obs_b.sel(latitude=0, longitude=0).mean('category').precip, ref_obs_month1)\n",
    "\n",
    "    print(\"\\nFORECASTS PROBABILITIES TESTS PASSED\")\n",
    "ref_probas_month1_issue1 = test_calculate_forecast_probabilities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_evaluate_forecast_probabilities():\n",
    "    _, _, test_probas, test_probas_bc, test_obs_levels = get_test_input()\n",
    "    test_auc, test_auc_bc = evaluate_forecast_probabilities(test_probas, test_probas_bc, test_obs_levels)\n",
    "\n",
    "    xr.testing.assert_allclose(test_auc, xr.DataArray(0.45192308))\n",
    "    xr.testing.assert_allclose(test_auc_bc, xr.DataArray(0.19230769))\n",
    "\n",
    "    print(\"\\nFORECASTS VERIFICATION TESTS PASSED\")\n",
    "\n",
    "test_evaluate_forecast_probabilities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison on the full output at the district level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(comparison, title, xlabel, xmin, xmax, s=1, mask_text=False):\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots(figsize = (6,4))\n",
    "\n",
    "    quant_5, quant_25, quant_50, quant_75, quant_95 = comparison.difference.quantile(0.05), comparison.difference.quantile(0.25), comparison.difference.quantile(0.5), comparison.difference.quantile(0.75), comparison.difference.quantile(0.95)\n",
    "\n",
    "    # [quantile, opacity, length]\n",
    "    quants = [[quant_5, 0.6, 0.16], [quant_25, 0.8, 0.26], [quant_50, 1, 0.36],  [quant_75, 0.8, 0.46], [quant_95, 0.6, 0.56]]\n",
    "\n",
    "    comparison.difference.plot(kind='hist', density = True, alpha = 0.65, bins=200)\n",
    "    comparison.difference.plot(kind='kde')\n",
    "\n",
    "    # Plot the lines with a loop\n",
    "    import matplotlib.pyplot as plt\n",
    "    for i in quants: plt.axvline(i[0], alpha = i[1], ymax = i[2], linestyle = \":\")\n",
    "\n",
    "    # X\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_xlim(xmin, xmax) \n",
    "\n",
    "    # Y\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_ylabel(\"\")\n",
    "\n",
    "    if not(mask_text):\n",
    "        plt.text(quant_5-.01, 0.15 * s, \"5th\", size = 10, alpha = 0.8)\n",
    "        plt.text(quant_25-.013, 0.27 * s, \"25th\", size = 11, alpha = 0.85)\n",
    "        plt.text(quant_50-.013, 0.33 * s, \"50th\", size = 12, alpha = 1)\n",
    "        plt.text(quant_75-.013, 0.39 * s, \"75th\", size = 11, alpha = 0.85)\n",
    "        plt.text(quant_95-.025, 0.47 * s, \"95th Percentile\", size = 10, alpha =.8)\n",
    "\n",
    "    # Overall\n",
    "    ax.grid(False)\n",
    "    ax.set_title(title, size = 17, pad = 10)\n",
    "\n",
    "    # Remove ticks and spines\n",
    "    ax.tick_params(left = False, bottom = False)\n",
    "    for ax, spine in ax.spines.items():\n",
    "        spine.set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbfref = pd.read_csv('data/MOZ/outputs/Districts_FbF/spi/fbf.districts.roc.spi.2022.txt')\n",
    "fbfref.columns = ['district', 'category', 'AUC_ref', 'BC_ref', 'Index', 'issue']\n",
    "fbfref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_of_interest = \"blended\" # change with output name of dataset of interest\n",
    "\n",
    "fbfP = pd.read_csv('data/MOZ/outputs/Districts_FbF/spi/fbf.districts.roc.spi.2022.{data_of_interest}.txt')\n",
    "fbfP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ratio of bias-corrected values in the final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratio of cases using Bias Correction\n",
    "fbfP.BC.sum() / len(fbfP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram of difference between full outputs (auc_to_compare - python_reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = fbfP.set_index(['district', 'category', 'Index', 'issue']).join(fbfref.set_index(['district', 'category', 'Index', 'issue'])).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison['difference'] = comparison.AUC_best - comparison.AUC_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(comparison, title=\"R/Python AUC (BC and not) difference at the district level\", xlabel=\"AUC difference\", xmin=-.5, xmax=.5, s=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference (auc_to_compare - python_reference) on the full output by category / district / index / issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = [5, 6, 7, 8, 9, 10, 11, 12, 1, 2]\n",
    "y_axis = ['SPI ON', 'SPI ND', 'SPI DJ', 'SPI JF', 'SPI FM', 'SPI MA', 'SPI AM', 'SPI OND', 'SPI NDJ', 'SPI DJF', 'SPI JFM', 'SPI FMA', 'SPI MAM']\n",
    "\n",
    "def draw_heatmap(**kwargs):\n",
    "    data = kwargs.pop('data')\n",
    "    d = data.pivot(index=\"Index\", columns=\"issue\", values=\"difference\")\n",
    "    d = d.reindex(index=y_axis, columns=x_axis)\n",
    "    sns.heatmap(d, **kwargs)\n",
    "\n",
    "fg = sns.FacetGrid(comparison.loc[(comparison.category=='Severo')], col='district', col_wrap=4)\n",
    "fg.map_dataframe(draw_heatmap, annot=True, annot_kws={\"size\":4}, cbar=True, cmap='RdYlGn', center=0)\n",
    "fg.fig.subplots_adjust(top=0.9)\n",
    "fg.fig.suptitle('SEVERE CATEGORY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = sns.FacetGrid(comparison.loc[(comparison.category=='Moderado')], col='district', col_wrap=4)\n",
    "fg.map_dataframe(draw_heatmap, annot=True, annot_kws={\"size\":4}, cbar=True, cmap='RdYlGn', center=0)\n",
    "fg.fig.subplots_adjust(top=0.9)\n",
    "fg.fig.suptitle('MODERATE CATEGORY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = sns.FacetGrid(comparison.loc[(comparison.category=='Leve')], col='district', col_wrap=4)\n",
    "fg.map_dataframe(draw_heatmap, annot=True, annot_kws={\"size\":4}, cbar=True, cmap='RdYlGn', center=0)\n",
    "fg.fig.subplots_adjust(top=0.9)\n",
    "fg.fig.suptitle('MILD CATEGORY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation of differences for each pair of variables to highlight any systematic difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Average difference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = [5, 6, 7, 8, 9, 10, 11, 12, 1, 2]\n",
    "y_axis = ['SPI ON', 'SPI ND', 'SPI DJ', 'SPI JF', 'SPI FM', 'SPI MA', 'SPI AM', 'SPI OND', 'SPI NDJ', 'SPI DJF', 'SPI JFM', 'SPI FMA', 'SPI MAM']\n",
    "\n",
    "def draw_heatmap(**kwargs):\n",
    "    data = kwargs.pop('data')\n",
    "    d = data.pivot(index=\"Index\", columns=\"issue\", values=\"difference\")\n",
    "    d = d.reindex(index=y_axis, columns=x_axis)\n",
    "    sns.heatmap(d, **kwargs)\n",
    "\n",
    "fg = sns.FacetGrid(\n",
    "    comparison.groupby(['issue', 'Index', 'category']).mean('district').reset_index(), \n",
    "    col='category', \n",
    "    col_wrap=3\n",
    ")\n",
    "fg.map_dataframe(draw_heatmap, annot=True, annot_kws={\"size\":4}, cbar=True, cmap='RdYlGn', center=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = [5, 6, 7, 8, 9, 10, 11, 12, 1, 2]\n",
    "y_axis = [\"Chiure\", \"Chibuto\", \"Chicualacuala\", \"Guija\", \"Mabalane\", \"Mapai\", \"Massingir\", \"Caia\", \"Chemba\", \"Changara\", \"Marara\"]\n",
    "\n",
    "def draw_heatmap(**kwargs):\n",
    "    data = kwargs.pop('data')\n",
    "    d = data.pivot(index=\"district\", columns=\"issue\", values=\"difference\")\n",
    "    d = d.reindex(index=y_axis, columns=x_axis)\n",
    "    sns.heatmap(d, **kwargs)\n",
    "\n",
    "fg = sns.FacetGrid(\n",
    "    comparison.groupby(['issue', 'district', 'category']).mean('Index').reset_index(), \n",
    "    col='category', \n",
    "    col_wrap=3\n",
    ")\n",
    "fg.map_dataframe(draw_heatmap, annot=True, annot_kws={\"size\":4}, cbar=True, cmap='RdYlGn', center=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = ['SPI ON', 'SPI ND', 'SPI DJ', 'SPI JF', 'SPI FM', 'SPI MA', 'SPI AM', 'SPI OND', 'SPI NDJ', 'SPI DJF', 'SPI JFM', 'SPI FMA', 'SPI MAM']\n",
    "y_axis = [\"Chiure\", \"Chibuto\", \"Chicualacuala\", \"Guija\", \"Mabalane\", \"Mapai\", \"Massingir\", \"Caia\", \"Chemba\", \"Changara\", \"Marara\"]\n",
    "\n",
    "def draw_heatmap(**kwargs):\n",
    "    data = kwargs.pop('data')\n",
    "    d = data.pivot(index=\"district\", columns=\"Index\", values=\"difference\")\n",
    "    d = d.reindex(index=y_axis, columns=x_axis)\n",
    "    sns.heatmap(d, **kwargs)\n",
    "\n",
    "fg = sns.FacetGrid(\n",
    "    comparison.groupby(['Index', 'district', 'category']).mean('issue').reset_index(), \n",
    "    col='category', \n",
    "    col_wrap=3\n",
    ")\n",
    "fg.map_dataframe(draw_heatmap, annot=True, annot_kws={\"size\":4}, cbar=True, cmap='RdYlGn', center=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aa-drought",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
